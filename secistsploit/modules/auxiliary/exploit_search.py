# -*- coding: UTF-8 -*-
import re
import os
from bs4 import BeautifulSoup
from secistsploit.core.exploit import *
from secistsploit.core.http.http_client import HTTPClient

class Exploit(HTTPClient):
    __info__ = {
        "name": "exploit_search",
        "description": "exploit_search",
        "authors": (
            "jjiushi",
        ),
        "references": (
            "www.422926799.github.io"
            "www.422926799.github.io"
        ),

    }

    target=OptString("expku.com","exploit search")
    search=OptString("","Loopholes to search")
    port=OptPort(80,"Set HTTP Port")
    files=OptString("","You need to import dynamic nmap scan records")
    def __init__(self):
        self.endianness = "<"

    def run(self):
        urd=(self.target)
        ld=(self.search)
        files=(self.files)
        data={'typeid':'0',
              'tag':'0',
              'keyword':'{}'.format(ld),
              'Submit':'(unable to decode value)',
              }
        response= self.http_request(
            method="POST",
            path="/search.php",
            data=data,
        )

        hrefs=[]
        titles=[]
        products=[]
        versions=[]
        if response:
            bd=BeautifulSoup(str(response.text),'html.parser')
            for r in bd.find_all('a'):
                rps=re.findall('<a href="/.*" target="_blank" title=".*">',str(r))
                for p in rps:
                    href=re.findall('href="/.*?"',str(p))
                    for url in href:
                        qc=str(url).replace('"','').replace('href=','')
                        hrefs.append('http://expku.com{}'.format(qc))

                    title=re.findall('title=".*?"',str(p))
                    for tl in title:
                        qc2=str(tl).replace('title=','').replace('"','')
                        titles.append(qc2)

        for g in range(0,len(hrefs)):
            print('[+] url:{}   title:{}'.format(hrefs[g],titles[g]))

        if files!='' and ld=='':
            if os.path.exists(files):
                print('[+] Open {} ok'.format(files))
            else:
                print('[-] {} Not Found'.format(files))

            dk=open(files,'r')
            reads="".join(dk.read().split('\n'))
            product=re.findall('product=".*?"',str(reads))
            for k in product:
                sc=str(k).replace('product=','').replace('"','')
                products.append(sc)

            vers=re.findall('version=".*?"',str(reads))
            for v in vers:
                qc3=str(v).replace('version=','').replace('"','')
                versions.append(qc3)

            for ps in products:
                data = {'typeid': '0',
                        'tag': '0',
                        'keyword': '{}'.format(ps),
                        'Submit': '(unable to decode value)',
                        }
                response2 = self.http_request(
                    method="POST",
                    path="/search.php",
                    data=data,
                )

                if response2:
                    bd = BeautifulSoup(str(response2.text), 'html.parser')
                    for r in bd.find_all('a'):
                        rps = re.findall('<a href="/.*" target="_blank" title=".*">', str(r))
                        for p in rps:
                            href = re.findall('href="/.*?"', str(p))
                            for url in href:
                                qc = str(url).replace('"', '').replace('href=', '')
                                hrefs.append('http://expku.com{}'.format(qc))

                            title = re.findall('title=".*?"', str(p))
                            for tl in title:
                                qc2 = str(tl).replace('title=', '').replace('"', '')
                                titles.append(qc2)

                    for t in range(0,len(hrefs)):
                        print('[+] url:{}   title:{}'.format(hrefs[t],titles[t]))
